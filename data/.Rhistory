mutate(Time = ifelse(year >= 2021, 1, 0)) %>%
mutate(Treated = if_else(City == "Philadelphia",1,0))%>%
filter(City == "Philadelphia" | City == "Detroit")%>%
filter(year <= 2022)
#Running the Before- After Control Impact model
baci.model <- feols(nobs45km ~ Treated * Time, data = city.data.baci, cluster = "City")
summary(baci.model)
confint.baci <- confint(baci.model)
confint.baci
#shows significant increases in Philadelphia bee abundance when compared to Detroit
source("useful_functions.R")
?geom_point()
?geom_pointrange
baci.fig  %>%
ggplot(aes(x=term, y=estimate, ymin = conf.low, ymax = conf.high, colour = term)) +
geom_pointrange(size = 1.5, position = position_dodge(width = 0.5))
baci.fig
baci.fig  %>%
ggplot(aes(x=term, y=estimate, ymin = conf.low, ymax = conf.high, colour = term)) + geom_pointrange(size = 1.5, position = position_dodge(width = 0.5))
baci.fig  %>%
ggplot(aes(x=term, y=estimate, ymin = conf.low, ymax = conf.high, colour = term)) +
geom_pointrange(aes(col = reg), size = 1.5, position = position_dodge(width = 0.5)) +
scale_colour_discrete() +
#scale_color_manual(values=cbPalette[c(7,9,4,8)]) +
theme_classic()
baci.fig  %>%
ggplot(aes(x=term, y=estimate, ymin = conf.low, ymax = conf.high, colour = term)) + geom_pointrange(size = 1.5, position = position_dodge(width = 0.5))
ggplot(baci.fig, aes(x=term, y=estimate, ymin = conf.low, ymax = conf.high, colour = term)) + geom_pointrange(size = 1.5, position = position_dodge(width = 0.5))
baci.fig
baci.model <- feols(nobs45km ~ Treated * Time, data = city.data.baci, cluster = "City")
summary(baci.model)
city.data.baci2 <- city.data %>%
mutate(Time = ifelse(year >= 2021, 1, 0)) %>%
mutate(Treated = if_else(City == "Philadelphia",1,0))%>%
filter(City == "Philadelphia" | City == "Cleveland")%>%
filter(year <= 2022)
baci.model2 <- feols(nobs45km ~ Treated * Time, data = city.data.baci2, cluster = ~City)
summary(baci.model2)
source("~/Rfunctions/figure_functions.R")
baci.model2 <- feols(nobs45km ~ Treated * Time, data = city.data.baci2, cluster = "City")
summary(baci.model2)
baci.model2 <- feols(nobs45km ~ Treated * Time, data = city.data.baci2, cluster = "City")
summary(baci.model2)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("reshaped_2_byFlowEntry.csv")
library(tidyr)
library(dplyr)
names(docs) <- gsub("^X(\\d)", "\\1", names(docs))
glimpse(docs)
# Assuming the column name is `flow_type` (adjust it if necessary)
reshaped_data <- docs %>%
separate_rows(`2.1.Flow.Type`, sep = ", ") # Split the rows based on the comma and space
glimpse(reshaped_data)
dim(docs)
dim(reshaped_data)
reshaped_data$ID_DOI_by_Flow <- seq(1:dim(reshaped_data)[1])
max(reshaped_data$ID_DOI_by_FlowEntry)
write.csv(reshaped_data, 'data/reshaped_3_byFlow.csv')
#laura:
write.csv(reshaped_data, 'reshaped_3_byFlow.csv')
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("reshaped_3_byFlow.csv")
head(docs)
citations_to_remove <- c(“Nielsen, 2015, Global Change Biology”,  “Vaddey, 2010, Watershed Management”,
list(unique(docs$Citation))
citations_to_remove <- c("Chen, 2011, Journal of Sustainable Development", "Nielsen, 2015, Global Change Biology",
"Vaddey, 2010, Watershed Management")
docs <- docs  %>% filter(Citation != citations_to_remove)
docs <- docs  %>% filter(Citation != "citations_to_remove")
head(docs)
list(unique(docs$Citation))
length(unqiue(docs$Citation))
length(docs$Citation)
lengt(list(unique(docs$Citation)))
length(list(unique(docs$Citation)))
nrows(list(unique(docs$Citation)))
nrow(list(unique(docs$Citation)))
doc2 <- docs %>% filter(Citation != c("Chen, 2011, Journal of Sustainable Development", "Nielsen, 2015, Global Change Biology",
"Vaddey, 2010, Watershed Management"))
doc2 <- docs %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management"))
doc2 <- docs %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management")
list(unique(doc2$Citation))
list(unique(docs$Citation))
doc2 <- doc2 %>% filter(Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Noyes, 2009, Environment International")
# list of papers to remove that need to be recoded:
to_recode <- c("Jenkins et al., 2013, Advances in Parasitology", "Noyes, 2009, Environment International")
subflow_to_remove <-  doc2 %>% filter(ID_DOI_by_Flow ! = "95",
subflow_to_remove <-  doc2 %>% filter(ID_DOI_by_Flow != "95",
ID_DOI_by_Flow != "69")
# list of papers to remove that need to be recoded:
list_to_recode <- c("Jenkins et al., 2013, Advances in Parasitology", "Noyes, 2009, Environment International",
"Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT",
"Covich et al., 1997, Hydrological Processes")
doc2 <- doc2 %>% filter(Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Noyes, 2009, Environment International",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT")
subflow_to_remove <-  doc2 %>% filter(ID_DOI_by_Flow != "95",
ID_DOI_by_Flow != "69",
ID_DOI_by_Flow != "135")
write.csv(doc2, "cleaned_4_byFlow.csv")
#load look up tables
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
head(biotic)
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow")
head(updated_docs)
glimpse(updated_docs)
updated_docs <- merge(phys, docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, docs, by = "ID_DOI_by_Flow")
doc2 <- docs %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Perry, 2007, Climate Change 2007")
# list of papers to remove that need to be recoded:
list_to_recode <- c("Jenkins et al., 2013, Advances in Parasitology",
"Noyes, 2009, Environment International",
"Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT",
"Covich et al., 1997, Hydrological Processes")
doc2 <- doc2 %>% filter(Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Noyes, 2009, Environment International",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes") # #Mabel checking
# list of subflow entries (by_flow) to remove:
##** We need to think about how to do this if some have been recoded in the form
##*# then if we reload the data and reassign the #s - will this still work?
subflow_to_remove <-  doc2 %>% filter(ID_DOI_by_Flow != "95",
ID_DOI_by_Flow != "69",
ID_DOI_by_Flow != "135") # this is Dube et al 2012 that says River and groundwater flows along with sediment and pollunts and lists Biotic entry
###Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT" needs to be recoded.
# list of entire papers to remove that have been recoded and need to be replaced:
# de la Fontaine,  2018, Ecology
# Costa, D., 2021, Journal of Great Lakes Research
# Shin et al., 2021, Global Change Biology
## list of papers with at least one major flow that was reclassified and needs to be replaced
# or just have the Flow entry changed*** HOW TO BEST DO THIS?
# Hartig, 2021, Journal of Great Lakes Research, DOI_by_Flow #95 changed to Biotic (range shift)
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
write.csv(doc2, "cleaned_4_byFlow.csv")
## Reclassify Subflow Types and ReplaceEntries
# Feb 9 2025
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#Read in new entries that will be appended and assigned new IDs
# replace <- read.csv
# in the look up files, probably need to first remove the ones removed in the 004 step to avoid confusion
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(phys, docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, docs, by = "ID_DOI_by_Flow")
glimpse(updated_docs)
# Add in the new entries entirely:
# de la Fontaine,  2018, Ecology
# Costa, D., 2021, Journal of Great Lakes Research
# Shin et al., 2021, Global Change Biology
## Reclassify Subflow Types and ReplaceEntries
# Feb 9 2025
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#Read in new entries that will be appended and assigned new IDs
# replace <- read.csv
# in the look up files, probably need to first remove the ones removed in the 004 step to avoid confusion
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(phys, docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, docs, by = "ID_DOI_by_Flow")
glimpse(updated_docs)
# Add in the new entries entirely:
# de la Fontaine,  2018, Ecology
# Costa, D., 2021, Journal of Great Lakes Research
# Shin et al., 2021, Global Change Biology
write.csv(updated_docs, "cleaned_5_byFlow.csv")
table(updated_docs$X2.2.Subtype.NEW)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
updated_docs <- merge(docs, socio, by = "ID_DOI_by_Flow")
table(updated_docs$X2.2.Subtype.NEW)
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow", all.x = T, all.y = T)
table(updated_docs$X2.2.Subtype.NEW)
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow", all.x = T, all.y = T)
table(updated_docs$X2.2.Subtype.NEW)
updated_docs <- merge(phys, updated_docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, updated_docs, by = "ID_DOI_by_Flow")
glimpse(updated_docs)
table(updated_docs$X2.1.Flow.Type.NEW)
updated_docs <- merge(phys, updated_docs, by = "ID_DOI_by_Flow")
table(updated_docs$X2.1.Flow.Type.NEW)
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow", all.x = T, all.y = T)
updated_docs <- merge(phys, updated_docs, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, updated_docs, by = "ID_DOI_by_Flow")
glimpse(updated_docs)
table(updated_docs$X2.2.Subtype.NEW )
library(tidyr)
library(dplyr)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, docs, by = "ID_DOI_by_Flow", all.y = T)
updated_docs
updated_docs <- merge(phys, updated_docs, by = "ID_DOI_by_Flow", all.y = T)
updated_docs <- merge(biotic, updated_docs, all.y = T, by = "ID_DOI_by_Flow")
updated_docs <- merge(biotic, updated_docs, by = "ID_DOI_by_Flow", all.y = T)
# Merge the new subflows into the main dataset
updated_docs <- merge(socio, phys, by = "ID_DOI_by_Flow", all.y = T)
head(updated_docs)
table(updated_docs$X2.2.Subtype.NEW.y)
#merge subflows into a single datafile
subflows <- merge(socio, phys, by = "ID_DOI_by_Flow", all.y = T)
subflows <- merge(biotic, subflows, by = "ID_DOI_by_Flow", all.y = T)
table(subflows$X2.2.Subtype.NEW)
glimpse(subflows)
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#merge subflows into a single datafile
subflows <- merge(socio, phys, by = "ID_DOI_by_Flow", all.y = T)
glimpse(subflows)
#merge subflows into a single datafile
subflows <- merge(socio, phys, all.y = T)
glimpse(subflows)
subflows <- merge(biotic, subflows,  all.y = T)
glimpse(subflows)
table(subflows$X2.2.Subtype.NEW)
# Merge the new subflows into the main dataset
updated_docs <- merge(subflows, updated_docs, all.y = T)
glimpse(updated_docs)
docs <- read.csv("cleaned_4_byFlow.csv")
# Merge the new subflows into the main dataset
updated_docs <- merge(subflow, docs, by = "ID_DOI_by_Flow", all.y = T)
# Merge the new subflows into the main dataset
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
glimpse(updated_docs)
write.csv(updated_docs, "cleaned_5_byFlow.csv")
summary(updated_docs$X2.2.Subtype.NEW)
table(updated_docs$X2.2.Subtype.NEW)
#clean so all of the range shifts are the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW:= "Range shift"]
library(data.table)
#clean so all of the range shifts are the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW:= "Range shift"]
#clean so all of the range shifts are the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW:= "Range shift"]
updated_docs[X2.2.Subtype.NEW == "range shift", X2.2.Subtype.NEW := "Range shift"]
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
table(updated_docs$X2.2.Subtype.NEW)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW:= "Range shift"]
updated_docs <- is.data.table(updated_docs)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
updated_docs[X2.2.Subtype.NEW == "range shift", X2.2.Subtype.NEW := "Range shift"]
table(updated_docs$X2.2.Subtype.NEW)
table(updated_docs$X2.2.Subtype.NEW)
glimpse(updated_docs)
# Merge the new subflows into the main dataset
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
glimpse(updated_docs)
table(updated_docs$X2.2.Subtype.NEW)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
table(updated_docs$X2.2.Subtype.NEW)
updated_docs <- is.data.table(updated_docs)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
head(updated_docs)
## Reclassify Subflow Types and ReplaceEntries
# Feb 9 2025
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
library(data.table)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#Read in new entries that will be appended and assigned new IDs
# replace <- read.csv
# in the look up files, probably need to first remove the ones removed in the 004 step to avoid confusion
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
#merge subflows into a single datafile
subflows <- merge(socio, phys, all.y = T)
subflows <- merge(biotic, subflows,  all.y = T)
# Merge the new subflows into the main dataset
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
glimpse(updated_docs)
table(updated_docs$X2.2.Subtype.NEW)
#clean entries so all of the range shifts are written the same
#updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
#updated_docs[X2.2.Subtype.NEW == "range shift", X2.2.Subtype.NEW := "Range shift"]
# Add in the new entries entirely for:
# de la Fontaine,  2018, Ecology
# Costa, D., 2021, Journal of Great Lakes Research
# Shin et al., 2021, Global Change Biology
write.csv(updated_docs, "cleaned_5_byFlow.csv")
table(updated_docs$X2.2.Subtype.NEW)
table(updated_docs$2.2.Subtype.NEW)
# Merge the new subflows into the main dataset
updated_docs <- merge(subflows, docs, by = "ID_DOI_by_Flow", all.y = T)
glimpse(updated_docs)
#clean entries so all of the range shifts are written the same
updated_docs[X2.2.Subtype.NEW == "range shifts", X2.2.Subtype.NEW := "Range shift"]
rm(list = ls())
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
library(data.table)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
#merge subflows into a single datafile
subflows <- merge(socio, phys, all.y = T)
subflows <- merge(biotic, subflows,  all.y = T)
glimpse(subflows)
rm(list = ls())
# ****TO DO STIL BEFORE THIS STEP -- #need to figure out what to do with the FLOW itself that have been changed***
library(tidyr)
library(dplyr)
library(data.table)
setwd("/Users/lade8828/Library/CloudStorage/OneDrive-UCB-O365/Documents/GitHub/BCCAch7/data")
docs <- read.csv("cleaned_4_byFlow.csv")
#load look up tables
#need to figure out what to do with the FLOW itself that have been changed
biotic <- read.csv("./data_cleaning/bioticFlowSubtype_lookup.csv")
socio <- read.csv("./data_cleaning/socioculturalFlowSubtype_lookup.csv")
phys <-  read.csv("./data_cleaning/physicalFlowSubtype_lookup.csv")
#Read in new entries that will be appended and assigned new IDs
# replace <- read.csv
# in the look up files, probably need to first remove the ones removed in the 004 step to avoid confusion
phys <- phys %>% filter(Citation != "Chen, 2011, Journal of Sustainable Development",
Citation != "Nielsen, 2015, Global Change Biology",
Citation != "Vaddey, 2010, Watershed Management",
Citation != "Jenkins et al., 2013, Advances in Parasitology",
Citation != "Dube et al., 2012, INTEGRATED ENVIRONMENTAL ASSESSMENT AND MANAGEMENT", #Mabel checking
Citation != "Covich et al., 1997, Hydrological Processes",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
biotic <- biotic %>% filter(Citation != "Noyes, 2009, Environment International",
Citation != "de la Fontaine,  2018, Ecology",
Citation != "Perry, 2007, Climate Change 2007")
socio <- socio %>% filter(Citation != "Shin et al., 2021, Global Change Biology")
#merge subflows into a single datafile
subflows <- merge(socio, phys, all.y = T)
subflows <- merge(biotic, subflows,  all.y = T)
glimpse(subflows)
#combine subflows look ups into a single datafile
rbind(biotic, phys)
subflows <- rbind(biotic, phys)
subflows <- rbind(socio, phys)
---
title: "Tutorial on propensity score matching and inverse probability of treatment weighting"
library(tidyverse)
library(MatchIt)
simulate_data <- function(){
### Create variables in a dataframe
### Make column for observation ID
df <- data.frame(id = seq(1,1000),
### Add columns for explanatory variables
### Add column for treatment variable
fire = c(rep(0,500), rep(1,500)),
### And the rest of the covariates
slope = c(runif(500, min = 50, max = 90),
runif(500, min = 65, max = 150)),
elevation = c(runif(500, min = 150, max = 185),
runif(500, min = 165, max = 200)),
stream = runif(1000, min = 0, max = 1),
### And the error term
error = rnorm(1000, mean = 0, sd = 5))
### Add a slope*slope variable
df <- df %>%
mutate(slope2 = slope^2)
### Make column for outcome variable (species richness)
df <- df %>%
mutate(species_richness = 1 + 5*fire + 0.07*slope + 0.05*elevation + 2*stream - 0.005*slope2 + error)
return(df)
}
ols_fun <- function(){
### Simulate the dataset
data <- simulate_data()
### Run OLS regression
ols <- lm(species_richness ~ fire + slope + elevation + stream,
data = data)
### Extract model coefficients and standard error
fire_coeff <- coef(summary(ols))["fire", "Estimate"]
fire_se <- coef(summary(ols))["fire", "Std. Error"]
list <- list(fire_coeff, fire_se)
}
### Apply the function to 100 replicates
ols_sim <- replicate(100, ols_fun())
### Extract the model estimates
ols_fire_est <- unlist(ols_sim[1, ])
### Print mean, standard deviation, minimum, and maximum values for coefficient estimates
c(mean(ols_fire_est), sd(ols_fire_est),
min(ols_fire_est), max(ols_fire_est))
### Extract the standard deviations
ols_fire_sd <- unlist(ols_sim[2, ])
### Print mean, standard deviation, minimum, and maximum standard deviation of coefficient estimates
c(mean(ols_fire_sd), sd(ols_fire_sd),
min(ols_fire_sd), max(ols_fire_sd))
```
---
title: "Matching in R"
